{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import testimony.graph as graph\n",
      "import testimony.nameutils as nameutils\n",
      "import testimony.testimony_utils as testimony_utils\n",
      "\n",
      "transcripts = testimony_utils.Transcripts()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Getting speech acts...\n",
        "Merging..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "from classifier import Sentence\n",
      "import nltk\n",
      "import ner\n",
      "\n",
      "G = nx.read_gml('graphs/unweighted.gml')\n",
      "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
      "tagger = ner.SocketNER(host='localhost', port=8080)\n",
      "# --------------------------------------------------------\n",
      "\n",
      "\n",
      "def people_mentioned_in_single_speechact(speechact):\n",
      "    \"returns a list of mentioned people from a single speechact \"\n",
      "    people = []\n",
      "    sens = tokenizer.tokenize(speechact)\n",
      "    for sen in sens:\n",
      "        entities_dict = tagger.get_entities(sen)\n",
      "        if entities_dict.has_key('PERSON'):\n",
      "            people.extend(entities_dict['PERSON'])\n",
      "    return people\n",
      "    \n",
      "    \n",
      "def people_mentioned_in_speechacts(speechacts):\n",
      "    \"retrieves a list of mentioned people from a list of speechacts\"\n",
      "    people = []\n",
      "    for speechact in speechacts:\n",
      "        people.extend(people_mentioned_in_single_speechact(speechact))\n",
      "    return people\n",
      "\n",
      "\n",
      "def naming_data_from_speechacts(speechact_dict):\n",
      "    entity_data = {} # name -> [entities]\n",
      "    for speaker, speechacts in speechact_dict.items():\n",
      "        mentioned_people = people_mentioned_in_speechacts(speechacts)\n",
      "        entity_data[speaker] = list(set(mentioned_people)) #get rid of duplicates (for now)\n",
      "    return entity_data\n",
      "\n",
      "def naming_data_for_node(node):\n",
      "    \"naming data from the transcripts for a particular node\"\n",
      "    name = transcripts.get_closest_name(node['label'], True)\n",
      "    if not name: \n",
      "        return {}\n",
      "    speechact_dict_from_testimony = transcripts.get_speech_acts_from_testimony(name.replace(\" \", \"-\"))\n",
      "    \n",
      "    return naming_data_from_speechacts(speechact_dict_from_testimony)\n",
      "\n",
      "\n",
      "naming_data_from_transcripts = {} #bad name, because keys are from graph.\n",
      "for id in G.nodes_iter():\n",
      "    node = G.node[id]\n",
      "    naming_data_from_transcripts[node['label']] = naming_data_for_node(node)\n",
      "    "
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame\n",
      "\n",
      "def is_close_to_name_in_transcripts(graph_name):\n",
      "    closest_name = transcripts.get_closest_name(graph_name)\n",
      "    if closest_name:\n",
      "        return closest_name\n",
      "    # for transcript_name in naming_data_from_transcripts.keys():\n",
      "    #     if nameutils.are_close_tokens(transcript_name, graph_name, 0.3):\n",
      "    #         return transcript_name\n",
      "    return False\n",
      "\n",
      "# names from graph\n",
      "graph_names = []\n",
      "in_transcripts = []\n",
      "for id in G.nodes_iter():\n",
      "    node = G.node[id]\n",
      "    name = node['label']\n",
      "    graph_names.append(name)\n",
      "    in_transcripts.append(is_close_to_name_in_transcripts(name))\n",
      "\n",
      "data = {'in transcripts' : in_transcripts}\n",
      "\n",
      "df = DataFrame(data, index=graph_names)\n",
      "\n",
      "df.head()\n"
     ],
     "language": "python",
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>in transcripts</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>lillian lowenfels</th>\n",
        "      <td>       False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>bart lytton</th>\n",
        "      <td> bart lytton</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>larry parks</th>\n",
        "      <td> larry parks</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>betty martin</th>\n",
        "      <td>       False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>jean richardson</th>\n",
        "      <td>       False</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "                  in transcripts\n",
        "lillian lowenfels          False\n",
        "bart lytton          bart lytton\n",
        "larry parks          larry parks\n",
        "betty martin               False\n",
        "jean richardson            False"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# problem: name taken from \n",
      "def all_names_from_hearing(name):\n",
      "    #name = transcripts.get_closest_name(name, True) # taking data from graph names, so....\n",
      "    if not name:\n",
      "        return []\n",
      "    data = naming_data_from_transcripts[name]\n",
      "    names = []\n",
      "    for k,v in naming_data_from_transcripts[name].items():\n",
      "        names.extend(v)\n",
      "    return list(set(names)) # remove duplicates\n",
      "\n",
      "def node_by_label(name):\n",
      "    for id in G.nodes_iter():\n",
      "        if name == G.node[id]['label']:\n",
      "            return id\n",
      "            # return G.node[id] #might need to return id instead\n",
      "\n",
      "\n",
      "def all_named_in_graph(name):\n",
      "    names = []\n",
      "    node = node_by_label(name)\n",
      "    for id in G.successors_iter(node):\n",
      "        names.append(G.node[id]['label'])\n",
      "    return names\n",
      "\n",
      "df_new = df.copy()\n",
      "n_in_g_not_t = []\n",
      "n_in_t_not_g = []\n",
      "\n",
      "\n",
      "in_transcripts = []\n",
      "in_graph = []\n",
      "t_not_g = []\n",
      "g_not_t = []\n",
      "    \n",
      "for name in df.index:\n",
      "    mentioned_in_transcripts = all_names_from_hearing(name)\n",
      "    named_in_graph = all_named_in_graph(name)\n",
      "    \n",
      "    in_transcripts.append(mentioned_in_transcripts)\n",
      "    in_graph.append(named_in_graph)\n",
      "    t_not_g.append(mentioned_in_transcripts != [] and named_in_graph == [])\n",
      "    g_not_t.append(mentioned_in_transcripts == [] and named_in_graph != [])\n",
      "\n",
      "df_new['mentioned in transcripts'] = in_transcripts\n",
      "df_new['named in graph'] = in_graph\n",
      "df_new['t_not_g'] = t_not_g\n",
      "df_new['g_not_t'] = g_not_t"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = []\n",
      "for index, row in df_new.iterrows():\n",
      "    if row['mentioned in transcripts']:\n",
      "        indices.append(index)\n",
      "len(indices)\n",
      "\n",
      "len(naming_data_from_transcripts)"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 182,
       "text": [
        "308"
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# people whose transcripts mention people, but who name noone in the\n",
      "#'who named whom' graph.\n",
      "# df_new[df_new['t_not_g']]\n",
      "\n",
      "# constructing a 'mention' graph, unweighted.\n",
      "\n",
      "G_mention = nx.Graph()\n",
      "\n",
      "mention_graph_dict = {}\n",
      "\n",
      "for index, row in df_new.iterrows():\n",
      "    for name in row['mentioned in transcripts']:\n",
      "        if mention_graph_dict.has_key(index):\n",
      "            mention_graph_dict[index].append(name)\n",
      "        else:\n",
      "            mention_graph_dict[index] = [name]\n",
      "        #G_mention.add_edge(index, name)\n"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distribution = nameutils.name_distribution_with_tokens(mention_graph_dict)\n",
      "    \n",
      "def fix_graph(graph, distribution):\n",
      "    \"\"\"\n",
      "    Fixes mispelled names in the graph using name chunking and the\n",
      "    name occurrence distribution.\n",
      "    \"\"\"\n",
      "    new_graph = {}\n",
      "    for name in graph.keys():\n",
      "        print(name)\n",
      "        mln = nameutils.most_likely_name(name, distribution)\n",
      "\n",
      "        # I treat `informers` as a set because from looking at the\n",
      "        # data, it seems that multiple occurrences is usually an\n",
      "        # error.\n",
      "        informers = set()\n",
      "        for informer in graph[name]:\n",
      "            if not isinstance(informer, basestring):\n",
      "                continue\n",
      "            informer_mln = nameutils.most_likely_name(informer, distribution)\n",
      "            informers.add(informer_mln)\n",
      "\n",
      "        if new_graph.has_key(mln):\n",
      "            new_graph[mln].update(informers)\n",
      "        else:\n",
      "            new_graph[mln] = informers\n",
      "\n",
      "    return new_graph\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mention_graph_with_nodes_from_summaries= fix_graph(mention_graph_dict, distribution)\n",
      "nx.write_gml(mention_graph_with_nodes_from_summaries, \"graphs/mention_graph_with_nodes_from_summaries.gml\")\n",
      "    "
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 175,
       "text": [
        "78"
       ]
      }
     ],
     "prompt_number": 175
    }
   ]
  },
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "outputs": []
    }
   ]
  }
 ]
}